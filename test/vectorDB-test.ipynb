{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"langchain==0.2.6\"\n",
    "# !pip install \"ibm-watsonx-ai==1.0.10\"\n",
    "# !pip install \"langchain_ibm==0.1.8\"\n",
    "# !pip install \"langchain_community==0.2.6\"\n",
    "# !pip install \"sentence-transformers==3.0.1\"\n",
    "# !pip install \"chromadb==0.5.3\"\n",
    "# !pip install \"pydantic==2.8.2\"\n",
    "# !pip install \"langchain-huggingface==0.0.3\"\n",
    "# !pip install \"python-dotenv==1.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysqlite3-binary in /home/ibmuser03/.venv/lib64/python3.12/site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "!pip install pysqlite3-binary\n",
    "__import__('pysqlite3')\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "##################################\n",
    "# LangChain & Watsonx imports\n",
    "##################################\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import WatsonxLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "##################################\n",
    "# Watsonx Credentials\n",
    "##################################\n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "wml_credentials = {\n",
    "    \"apikey\": os.getenv(\"API_KEY\", None),\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"  # region url\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Utility Functions\n",
    "##################################\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text가 문자열이 아닐 경우(예: list, dict) 등을 처리해주는 버전\n",
    "    \"\"\"\n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(str(t) for t in text)\n",
    "    elif not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def _extract_table_item(table_dict: dict, results: list):\n",
    "    \"\"\"\n",
    "    '별표단위' 한 요소(별표번호, 별표제목, 별표내용) 전처리\n",
    "    \"\"\"\n",
    "    table_num = clean_text(table_dict.get(\"별표번호\", \"\"))\n",
    "    table_title = clean_text(table_dict.get(\"별표제목\", \"\"))\n",
    "    if table_num or table_title:\n",
    "        results.append(f\"(별표번호) {table_num} (별표제목) {table_title}\")\n",
    "\n",
    "    table_contents = table_dict.get(\"별표내용\", [])\n",
    "    if isinstance(table_contents, list):\n",
    "        for paragraph_list in table_contents:\n",
    "            if isinstance(paragraph_list, list):\n",
    "                for line in paragraph_list:\n",
    "                    if isinstance(line, str):\n",
    "                        txt = clean_text(line)\n",
    "                        if txt:\n",
    "                            results.append(txt)\n",
    "\n",
    "def extract_text_from_law_json(json_data: dict) -> list:\n",
    "    \"\"\"\n",
    "    법령 JSON에서 텍스트를 추출하여 문자열 리스트로 반환\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    law = json_data.get(\"법령\", {})\n",
    "\n",
    "    # (1) 법령명\n",
    "    law_name = law.get(\"기본정보\", {}).get(\"법령명_한글\", \"\")\n",
    "    results.append(f\"[{clean_text(law_name)}]\")\n",
    "\n",
    "    # (2) 부칙\n",
    "    sup_provisions = law.get(\"부칙\", {}).get(\"부칙단위\", [])\n",
    "    for sup_provision in sup_provisions:\n",
    "        content = sup_provision.get(\"부칙내용\", [])\n",
    "        for paragraph_list in content:  # 2차원 리스트\n",
    "            cleaned_line = []\n",
    "            for line in paragraph_list:\n",
    "                line = clean_text(line)\n",
    "                if line:\n",
    "                    cleaned_line.append(line)\n",
    "            merged = \"\".join(cleaned_line)\n",
    "            if merged:\n",
    "                results.append(merged)\n",
    "\n",
    "    # (3) 조문\n",
    "    provisions = law.get(\"조문\", {}).get(\"조문단위\", [])\n",
    "    for provision in provisions:\n",
    "        article_text = clean_text(provision.get(\"조문내용\", \"\"))\n",
    "        if article_text:\n",
    "            results.append(article_text)\n",
    "\n",
    "        # 항\n",
    "        if \"항\" in provision:\n",
    "            if isinstance(provision[\"항\"], dict):\n",
    "                ho_list = provision[\"항\"].get(\"호\", [])\n",
    "                if isinstance(ho_list, list):\n",
    "                    for ho_item in ho_list:\n",
    "                        ho_text = clean_text(ho_item.get(\"호내용\", \"\"))\n",
    "                        if ho_text:\n",
    "                            results.append(ho_text)\n",
    "            elif isinstance(provision[\"항\"], list):\n",
    "                for paragraph_item in provision[\"항\"]:\n",
    "                    if isinstance(paragraph_item, dict):\n",
    "                        para_text = clean_text(paragraph_item.get(\"항내용\", \"\"))\n",
    "                        if para_text:\n",
    "                            results.append(para_text)\n",
    "\n",
    "                        if \"호\" in paragraph_item:\n",
    "                            ho_list = paragraph_item[\"호\"]\n",
    "                            if isinstance(ho_list, list):\n",
    "                                for ho_item in ho_list:\n",
    "                                    ho_text = clean_text(ho_item.get(\"호내용\", \"\"))\n",
    "                                    if ho_text:\n",
    "                                        results.append(ho_text)\n",
    "\n",
    "    # (4) 별표\n",
    "    if \"별표\" in law:\n",
    "        annex_container = law[\"별표\"]\n",
    "        if isinstance(annex_container, dict):\n",
    "            table_list = annex_container.get(\"별표단위\", [])\n",
    "            if isinstance(table_list, list):\n",
    "                for table_item in table_list:\n",
    "                    if isinstance(table_item, dict):\n",
    "                        _extract_table_item(table_item, results)\n",
    "\n",
    "    return results\n",
    "\n",
    "def chunk_text(text_list: list, max_chunk_size: int = 500) -> list:\n",
    "    \"\"\"\n",
    "    긴 텍스트를 일정 크기로 분할\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for text in text_list:\n",
    "        if len(text) <= max_chunk_size:\n",
    "            chunks.append(text)\n",
    "        else:\n",
    "            start = 0\n",
    "            while start < len(text):\n",
    "                end = start + max_chunk_size\n",
    "                chunks.append(text[start:end])\n",
    "                start = end\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) laws 디렉토리 모든 JSON 파싱 & Chroma 벡터 DB 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laws/형의집행및수용자의처우에관한법률시행령.json',\n",
       " 'laws/자동차손해배상보장법.json',\n",
       " 'laws/형법.json',\n",
       " 'laws/자동차손해배상보장법시행규칙.json',\n",
       " 'laws/교통사고처리특례법.json',\n",
       " 'laws/도로교통법시행령.json',\n",
       " 'laws/자동차손해배상보장법시행령.json',\n",
       " 'laws/교통사고처리특례법시행령.json',\n",
       " 'laws/도로교통법.json',\n",
       " 'laws/형의집행및수용자의처우에관한법률.json',\n",
       " 'laws/민법.json',\n",
       " 'laws/특정범죄가중처벌등에관한법률.json',\n",
       " 'laws/도로교통법시행규칙.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_dir = \"laws\"\n",
    "json_files = glob.glob(os.path.join(laws_dir, \"*.json\"))\n",
    "json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 13620 chunks extracted.\n"
     ]
    }
   ],
   "source": [
    "all_docs = []\n",
    "all_metadatas = []\n",
    "\n",
    "for file_path in json_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    extracted_texts = extract_text_from_law_json(json_data)\n",
    "    # 청크 분할\n",
    "    chunks = chunk_text(extracted_texts, max_chunk_size=500)\n",
    "    for c in chunks:\n",
    "        all_docs.append(c)\n",
    "        # 예: 파일명 메타\n",
    "        all_metadatas.append({\"source_file\": os.path.basename(file_path)})\n",
    "\n",
    "print(f\"Total {len(all_docs)} chunks extracted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\" # 차원: 384 (속도 빠르고, 영어 중심의 성능이 준수하다고 함.)\n",
    "# persist_directory = 'chroma_db'\n",
    "\n",
    "# EMBEDDING_MODEL = \"sentence-transformers/multi-qa-mpnet-base-cos-v1\" #768차원 (검색 QA 성능이 우수하다고 함)\n",
    "# persist_directory = \"chroma_db_mpnet\"\n",
    "\n",
    "EMBEDDING_MODEL = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\" \n",
    "persist_directory = \"chroma_db_krsbert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 실행시 (임베딩 후 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "docsearch = Chroma.from_texts(\n",
    "    texts=all_docs,\n",
    "    embedding=embeddings,\n",
    "    metadatas=all_metadatas,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "docsearch.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 재시작시(DB 로딩만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibmuser03/.venv/lib64/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "docsearch = Chroma(\n",
    "    persist_directory=persist_directory,      # DB가 저장된 폴더\n",
    "    embedding_function=embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mdocsearch\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m})\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# resutls = retriever.get_relevant_documents(\"퓨리오사가 한 쪽 팔을 잃게되는 경위가 뭔가요?\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# resutls = retriever.get_relevant_documents(\"한강 작가는 언제 노벨문학상상을 받았나요?\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mget_relevant_documents(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m음주운전 관련 처벌에 대하여 알려줘\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docsearch' is not defined"
     ]
    }
   ],
   "source": [
    "retriever = docsearch.as_retriever(search_kwargs={'k': 5})\n",
    "# resutls = retriever.get_relevant_documents(\"퓨리오사가 한 쪽 팔을 잃게되는 경위가 뭔가요?\")\n",
    "# resutls = retriever.get_relevant_documents(\"한강 작가는 언제 노벨문학상상을 받았나요?\")\n",
    "results = retriever.get_relevant_documents(\"음주운전 관련 처벌에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source_file': '도로교통법시행령.json'}, page_content='3. 음주운전의 위험성 및 예방 필요성'),\n",
       " Document(metadata={'source_file': '도로교통법시행규칙.json'}, page_content='3. 음주운전의 위험성 및 예방 필요성'),\n",
       " Document(metadata={'source_file': '도로교통법시행령.json'}, page_content='2. 음주운전 방지장치의 작동방법'),\n",
       " Document(metadata={'source_file': '도로교통법시행규칙.json'}, page_content='2. 음주운전 방지장치의 작동방법'),\n",
       " Document(metadata={'source_file': '자동차손해배상보장법시행령.json'}, page_content='3. 무면허운전 및 음주운전 여부')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WatsonLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL= \"ibm/granite-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLM_MODEL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m      4\u001b[0m wml_credentials \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapikey\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://us-south.ml.cloud.ibm.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      9\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mDECODING_METHOD: DecodingMethods\u001b[38;5;241m.\u001b[39mGREEDY\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m     11\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mTOP_K: \u001b[38;5;241m50\u001b[39m,       \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mSTOP_SEQUENCES: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m watsonx_llama2_korean \u001b[38;5;241m=\u001b[39m WatsonxLLM(\n\u001b[0;32m---> 19\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[43mLLM_MODEL\u001b[49m,\n\u001b[1;32m     20\u001b[0m     url\u001b[38;5;241m=\u001b[39mwml_credentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     21\u001b[0m     apikey\u001b[38;5;241m=\u001b[39mwml_credentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapikey\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     22\u001b[0m     project_id\u001b[38;5;241m=\u001b[39mproject_id,\n\u001b[1;32m     23\u001b[0m     params\u001b[38;5;241m=\u001b[39mparameters\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# RAG Retrieval\u001b[39;00m\n\u001b[1;32m     27\u001b[0m retriever \u001b[38;5;241m=\u001b[39m docsearch\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LLM_MODEL' is not defined"
     ]
    }
   ],
   "source": [
    "# LLM 모델 준비\n",
    "\n",
    "project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "wml_credentials = {\n",
    "    \"apikey\": os.getenv(\"API_KEY\", None),\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY.value,\n",
    "    GenParams.TOP_K: 50,       \n",
    "    # GenParams.TOP_P: 0.90,       \n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 800,\n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"],\n",
    "}\n",
    "\n",
    "watsonx_llama2_korean = WatsonxLLM(\n",
    "    model_id=LLM_MODEL,\n",
    "    url=wml_credentials[\"url\"],\n",
    "    apikey=wml_credentials[\"apikey\"],\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")\n",
    "\n",
    "# RAG Retrieval\n",
    "retriever = docsearch.as_retriever(search_kwargs={'k': 8})\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{system_input}\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "# chain = chat_prompt | watsonx_llama2_korean\n",
    "qa = RetrievalQA.from_chain_type(llm=watsonx_llama2_korean, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '음주운전을 하면 어떤 처벌을 받아?',\n",
       " 'result': '\\n\\n음주운전은 대한민국의 법률에 따라 심각한 처벌을 받을 수 있습니다. 제50조의3제4항을 위반하여 음주운전 방지장치를 해체하거나 조작하는 경우, 3년 이하의 징역 또는 3천만원 이하의 벌금에 처해집니다. 또한, 제50조의3제5항을 위반하여 조건부 운전면허를 받은 사람을 대신하여 음주운전 방지장치가 설치된 자동차를 운전할 수 있도록 하는 경우, 1년 이하의 징역 또는 300만원 이하의 벌금에 처해집니다. 술에 취한 상태에서 자동차를 운전하는 경우, 제44조제1항을 위반하여 다음 각 호의 구분에 따라 처벌을 받을 수 있습니다.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"음주운전을 하면 어떤 처벌을 받아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User question: 음주운전을 하면 어떤 처벌을 받아?\n",
      "\n",
      "### Response ###\n",
      " \n",
      "\n",
      "System: 음주운전에 대한 처벌은 대한민국 법률에 따라 다음과 같습니다.\n",
      "\n",
      "1. **음주운전 처벌 법률**: 대한민국에서는 2018년 1월 1일부터 음주운전에 대한 처벌이 강화되었습니다. 이는 '음주운전 처벌 법률'에 의해 규정됩니다.\n",
      "\n",
      "2. **음주운전 처벌 규정**:\n",
      "   - **음주운전 처벌 범위**: 음주운전은 BAC(혈중알코올농도)가 0.05% 이상인 경우에 해당합니다.\n",
      "   - **처벌 규정**:\n",
      "     - **BAC 0.05% - 0.079%**: 처벌금 10만 원, 6개월 이하의 징역 또는 징역 1년 이하, 운전면허 취소 6개월 이하.\n",
      "     - **BAC 0.08% - 0.099%**: 처벌금 20만 원, 6개월 이하의 징역 또는 징역 2년 이하, 운전면허 취소 1년 이하.\n",
      "     - **BAC 0.10% 이상**: 처벌금 30만 원, 6개월 이하의 징역 또는 징역 3년 이하, 운전면허 취소 2년 이하.\n",
      "\n",
      "3. **추가 처벌**:\n",
      "   - **사망사고**: 음주운전으로 인한 사망사고는 범죄로 처벌받을 수 있습니다.\n",
      "   - **사용 중인 약물**: 약물이나 약품을 사용하고 음주운전을 한 경우, 처벌은 더욱 심각해집니다.\n",
      "\n",
      "4. **재판 및 처벌**:\n",
      "   - 음주운전 사건은 경찰이 수사하고, 검찰이 재판을 진행합니다.\n",
      "   - 재판 결과에 따라 처벌은 다를 수 있습니다.\n",
      "\n",
      "5. **재정적 영향**:\n",
      "   - 처벌금, 벌금, 운전면허 취소 등의 재정적 영향은 음주운전에 따른 결과입니다.\n",
      "   - 또한, 운전면허 취소는 일시적이거나 영구적일 수 있습니다.\n",
      "\n",
      "6. **재활성화**:\n",
      "   - 운전면허 취소 후, 재활성화를 신청할 수 있습니다.\n",
      "   - 재활성화 신청 시, 재활성화 시험을 통과해야 합니다.\n",
      "\n",
      "7. **교육 및 예방**:\n",
      "   - 음주운전은 사회적 문제이며, 교육과 예방이 중요합니다.\n",
      "   - 음주운전 예방 교육 및 캠페인이 활발히 진행되고 있습니다.\n",
      "\n",
      "8. **국제적 관계**:\n",
      "   - 대한민국은 국제적인 협력을 통해 음주\n"
     ]
    }
   ],
   "source": [
    "query = \"음주운전을 하면 어떤 처벌을 받아?\"\n",
    "\n",
    "print(f\"\\nUser question: {query}\")\n",
    "response = chain.invoke({\n",
    "    \"system_input\": \"당신은 정직한 에이전트입니다. 대한민국 법률 데이터에 근거하여 최대한 간단하게 답해주세요.\",\n",
    "    \"user_input\": query\n",
    "})   \n",
    "print(\"\\n### Response ###\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
